## This script is a combining of both 07-SplitSondeData.R and 06-ReadCSVFromKorSoftware.R
# which were used to automatically format the data exported from Kor. Now, this script handles
# that
## Authors - Waheed Saroyia and Chrisopher Jamieson

### [INSTRUCTIONS]
# In order to have the data be automatically formatted, the exported CSV file must be renamed to
# "AllExports.csv" and put into the "KorFormat" folder. Then, this script can be exectuted.

## Load libraries being used
library(readr) # Reads data
library(dplyr) # Splits data

# Adds a list of global variables into the current environment from 00_Globals.r
# This portion of the code assumes that you are in the root of the repository
# - Root <- This is the root of the repository
#   - 01_Data
#     - MHK_Data
#       - ...
#   - 02_Scripts
#     - ...
#   - 03_Graphs
#     - ...
#   - ...
base::source(base::file.path("02_Scripts", "00_Globals.r"))

# This is the path to the exported Kor file
kor_file_path <- KOR_UNFORMATTED_DATA_ALL

## Guess the encoding of the file so that it can be read properly by R
# The return value is a tibble that is sorted from least probable to most probable
# This code assumes that the encoding with the highest probability is the correct one
possible_encoding <- as.character(guess_encoding(kor_file_path)[1, 1])

## R fails to read files encoded in ASCII for some reason; however, there's a solution!
# Because UTF-8 is a superset of ASCII, all ASCII characters are UTF-8 characters!
# So far, there have been no issues with treating ASCII files like UTF-8 files
if (possible_encoding == "ASCII") {
  possible_encoding <- "UTF-8"
}

## Kor creates "rep=," at the top of the file and it messes up R so this will remove that
# Remember to read the file with the correct encoding!
raw_file <- file(description = kor_file_path, encoding = possible_encoding)

# Read each line and check to see if "rep=" is the first line
lines <- readLines(raw_file)

if (lines[1] == "sep=,") {
  lines <- lines[-1] # Removes the first line
}

# Write the changes
writeLines(lines, kor_file_path)
# WARNING! This function will re-encode and modify the data (it deletes the first line)!

## Update the possible encoding
possible_encoding <- as.character(guess_encoding(kor_file_path)[1, 1])

## R fails to read files encoded in ASCII for some reason; however, there's a solution!
# Because UTF-8 is a superset of ASCII, all ASCII characters are UTF-8 characters!
# So far, there have been no issues with treating ASCII files like UTF-8 files
if (possible_encoding == "ASCII") {
  possible_encoding <- "UTF-8"
}

## Read the data from the modified (or not modified) Kor file
# Because it's a CSV file the delimiter is ","
exported_kor_file_data <- read_delim(kor_file_path, delim = ",", locale = locale(encoding = possible_encoding))

## Now, it's time to split the data by dates
# Using group_by, each element can be grouped according to its date
# Then, using group_split each group will be put into a separate tibble and then they all are stored in a list
split_data <- exported_kor_file_data |> 
  group_by(DATE) |>
  group_split()


## Helper function
# Creates the name for the file when it's saved
create_file_name <- function (date, error_appended = "") {
  return(paste("MHK_", date, "_profile", error_appended, ".csv", sep = ""))
}

## Now, it's time to export all of the data in the correct format!
# for each dataframe in the split_data dataframe, do
for (dataframe in split_data) {
  ## Overwrite the dataframe's column names for convenience 
  # (The names are X1 to XN where N is the number of columns. This was used before these two scripts 
  # were combined. idk why it was done this way but I don't see any issues with it as of now)
  colnames(dataframe) <- paste("X", 1:ncol(dataframe), sep = "")

  #if there are 49 rows in the table then make a vector from 12 - 0 with step -.25
  #else fill the vector with NA with the vector being how many rows are in tab
  #and set data_input_error = true
  data_input_error <- FALSE

  # The number of rows in the current dataframe
  dataframe_nrow <- nrow(dataframe)

  if (dataframe_nrow == 49) {
    # No error in the data
    depths_vector <- seq(from = 12, to = 0, by = -0.25)
  } else {
    data_input_error <- TRUE
    depths_vector <- rep(NA, nrow(dataframe))

    if (dataframe_nrow > 49)
      # Too much data
      error_type <- "[TOO MUCH]"
    else
      # Too little data
      error_type <- "[TOO LITTLE]"
  }

  # Create a data frame with the headings of the formatted csv
  formatted_data <- data.frame(
     lakeID = rep("MHK", nrow(dataframe)),
     Date = dataframe$X2,
     Time = dataframe$X1,
     Depth_m = depths_vector,
     temp_degC = dataframe$X24,
     doConcentration_mgpL = dataframe$X15,
     doSaturation_percent = dataframe$X14,
     chlorophyll_RFU = dataframe$X8,
     phycocyaninBGA_RFU_14C102008 = dataframe$X6,
     turbidity_Fnu = rep(NA, nrow(dataframe)),
     pH = dataframe$X20,
     orp_MV = rep(NA, nrow(dataframe)),
     specificConductivity_uSpcm = dataframe$X10,
     salinity_psu = dataframe$X12,
     tds_mgpL = dataframe$X11,
     waterPressure_barA = rep(NA, nrow(dataframe)),
     latitude = dataframe$X17,
     longitude = dataframe$X18,
     altitude_m = dataframe$X19,
     barometerAirHandheld_mbars = dataframe$X7
  )

  #flips the rows of the dataframe
  formatted_data <- formatted_data[nrow(formatted_data):1, ]

  # Format the date to be file name friendly
  date <- dataframe$X2[1]
  date_as_string <- sub("(\\d+)/(\\d+)/(\\d{4})$", "\\3/\\1/\\2", as.character(date))

  ## If there are no leading zeros for the month or day, then append a 0 to the string
  date_split <- strsplit(date_as_string, "/")

  year <- date_split[[1]][1]
  month <- date_split[[1]][2]
  day <- date_split[[1]][3]

  if (nchar(day) < 2) day <- paste("0", day, sep = "")
  if (nchar(month) < 2) month <- paste("0", month, sep = "")

  # Converts the date to a string
  date_as_string <- paste(year, month, day, sep = "_")

  # Path to the current file being created
  current_file_to_save <- file.path(KOR_FORMATTED_DATA_DIR, create_file_name(date_as_string))

  # If the file is already there, then DO NOT overwrite it!
  if (!file.exists(current_file_to_save)) {
    # Save the data frame to a CSV file with the new file path
    # If the file has mistakes, append [MISTAKE FOUND] to the file name
    if (data_input_error == TRUE)
      save_file_name <- create_file_name(date_as_string, error_type)
    else
      save_file_name <- create_file_name((date_as_string))

    # Since this file has mistakes, its name will be different an therefore current_file_to_save must be overwritten
    current_file_to_save <- file.path(KOR_FORMATTED_DATA_DIR, save_file_name)

    # Ensure the file with mistakes does not exist already
    if (!file.exists(current_file_to_save))
      readr::write_csv(formatted_data, current_file_to_save)

  }
}
